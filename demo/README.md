# Soperator Demo æ¶æ„è¯´æ˜

## Kind é›†ç¾¤æ¶æ„å±‚æ¬¡

Soperator demo ä½¿ç”¨ Kind (Kubernetes in Docker) è¿è¡Œï¼Œå½¢æˆäº†å¤šå±‚å®¹å™¨æ¶æ„ã€‚ç†è§£è¿™ä¸ªæ¶æ„å¯¹äºè°ƒè¯•å’Œç›‘æ§éå¸¸ï¿½ï¿½è¦ã€‚

## æ¶æ„å¯¹åº”å…³ç³»å›¾

```mermaid
graph TB
    %% ç¬¬ä¸€å±‚ï¼šä¸»æœº Docker å±‚
    subgraph "ä¸»æœº Docker"
        K1[kindest/node: soperator-demo-control-plane<br/>è¿è¡Œ: kube-apiserver, etcd, etc.]
        K2[kindest/node: soperator-demo-worker]
        K3[kindest/node: soperator-demo-worker2]
        K4[kindest/node: soperator-demo-worker3]
    end

    %% ç¬¬äºŒå±‚ï¼šKubernetes é›†ç¾¤èŠ‚ç‚¹ (1:1æ˜ å°„)
    subgraph "Kubernetes é›†ç¾¤èŠ‚ç‚¹"
        K1 --> CP[soperator-demo-control-plane]
        K2 --> W1[soperator-demo-worker]
        K3 --> W2[soperator-demo-worker2]
        K4 --> W3[soperator-demo-worker3]
    end

    %% ç¬¬ä¸‰å±‚ï¼šSoperator æ ¸å¿ƒç»„ä»¶ + Slurm é›†ç¾¤ Pods
    subgraph "Soperator + Slurm Pods"
        subgraph "slurm-operator (æ ¸å¿ƒæ§åˆ¶å™¨)"
            W3 --> P0[soperator-manager-85c7987877-rh8zp<br/>ğŸŸ© slurm_operator è¿›ç¨‹<br/>ç®¡ç†æ‰€æœ‰SlurmCluster CRD]
        end

        subgraph "controller-0 (åœ¨worker3ä¸Š)"
            W3 --> P1[controller-0]
            P1 --> IC1[ğŸŸ¦ munge: initå®¹å™¨<br/>mungedè¿›ç¨‹]
            P1 --> C1[ğŸŸ¦ slurmctld: ä¸»å®¹å™¨<br/>slurmctldè¿›ç¨‹]
        end

        subgraph "worker-0 (åœ¨workerä¸Š)"
            W1 --> P2[worker-0]
            P2 --> C2[ğŸŸ¦ slurmd: ä¸»å®¹å™¨<br/>slurmdè¿›ç¨‹]
        end

        subgraph "sconfigcontroller (åœ¨workerä¸Š)"
            W1 --> P3[sconfigcontroller-86cc985fc-5bswf]
            P3 --> IC2[ğŸŸ© init-dir: initå®¹å™¨]
            P3 --> C3[ğŸŸ© sconfigctrl: ä¸»å®¹å™¨<br/>sconfigcontrollerè¿›ç¨‹]
        end

        subgraph "login-0 (åœ¨worker2ä¸Š)"
            W2 --> P4[login-0]
            P4 --> IC3[ğŸŸ¦ munge: initå®¹å™¨<br/>mungedè¿›ç¨‹]
            P4 --> C4[ğŸŸ¦ sshd: ä¸»å®¹å™¨<br/>sshdè¿›ç¨‹]
        end

        subgraph "populate-jail (åœ¨worker2ä¸Š)"
            W2 --> P5[populate-jail-5f4kh]
            P5 --> C5[ğŸŸ© populate-jail: ä¸»å®¹å™¨<br/>jailåˆå§‹åŒ–è¿›ç¨‹]
        end

        subgraph "controller-placeholder (åœ¨å¤šä¸ªworkerä¸Š)"
            W1 --> P6[controller-placeholder-7lc4l]
            P6 --> IC4[ğŸŸ¦ munge: initå®¹å™¨<br/>mungedè¿›ç¨‹]
            P6 --> C6[ğŸŸ¦ slurmctld: ä¸»å®¹å™¨<br/>slurmctldè¿›ç¨‹]
        end
    end

    %% è¯´æ˜: Control-plane èŠ‚ç‚¹ä¸“é—¨è¿è¡ŒKubernetesç³»ç»Ÿç»„ä»¶ï¼Œä¸è¿è¡ŒSlurmå·¥ä½œè´Ÿè½½

    %% æ ·å¼
    classDef docker fill:#e1f5fe
    classDef k8s fill:#f3e5f5
    classDef pod fill:#e8f5e8
    classDef slurm fill:#e3f2fd
    classDef soperator fill:#e8f5e8
    classDef core fill:#c8e6c9

    class K1,K2,K3,K4 docker
    class CP,W1,W2,W3 k8s
    class P0,P1,P2,P3,P4,P5,P6 pod
    class P0 core
    class IC1,IC3,IC4 slurm
    class C1,C2,C4,C6 slurm
    class IC2,IC3,C5 soperator
```

## å®¹å™¨å’Œè¿›ç¨‹è¯¦è§£

### ğŸ¯ **æœ€å…³é”®çš„ Soperator è¿›ç¨‹**

| è¿›ç¨‹å | éƒ¨ç½²ä½ç½® | Pod/å®¹å™¨ | ä½œç”¨ | ä¸ºä»€ä¹ˆå¿…éœ€ |
|--------|----------|----------|------|------------|
| **slurm_operator** | `soperator` å‘½åç©ºé—´ | `soperator-manager-xxx`<br/>manager å®¹å™¨ | ğŸŸ© **æ ¸å¿ƒæ§åˆ¶å™¨**<br/>ç®¡ç†æ‰€æœ‰ SlurmCluster CRD | æ²¡æœ‰å®ƒï¼Œæ•´ä¸ª Slurm é›†ç¾¤æ— æ³•è¿è¡Œ |

#### **æŸ¥çœ‹ slurm_operator è¿›ç¨‹çš„å‘½ä»¤**
```bash
# æŸ¥çœ‹ Pod è¿è¡ŒçŠ¶æ€
kubectl get pods -n soperator -o wide

# æŸ¥çœ‹ slurm_operator è¿›ç¨‹
kubectl exec -n soperator soperator-manager-xxx -c manager -- ps aux | grep slurm_operator

# æŸ¥çœ‹ slurm_operator æ—¥å¿—
kubectl logs -n soperator soperator-manager-xxx -c manager

# æŸ¥çœ‹å¯åŠ¨å‚æ•°
kubectl get pod soperator-manager-xxx -n soperator -o jsonpath='{.spec.containers[0].args}'
```

### ğŸ¯ **Soperator é›†ç¾¤ä¸­çš„è¿›ç¨‹åˆ†ç±»**

| Pod åç§° | å®¹å™¨ç±»å‹ | å®¹å™¨åç§° | å…³é”®è¿›ç¨‹ | è¿›ç¨‹æ¥æº | ä½œç”¨æè¿° |
|---------|----------|----------|----------|----------|----------|
| controller-0 | initå®¹å™¨ | munge | `munged` | ğŸŸ¦ **Slurmå¤–éƒ¨é¡¹ç›®** | Slurmè®¤è¯æœåŠ¡ï¼Œæä¾›èŠ‚ç‚¹é—´èº«ä»½éªŒè¯ |
| controller-0 | ä¸»å®¹å™¨ | slurmctld | `slurmctld` | ğŸŸ¦ **Slurmå¤–éƒ¨é¡¹ç›®** | Slurmä¸»æ§åˆ¶å™¨ï¼Œç®¡ç†ä½œä¸šè°ƒåº¦å’Œèµ„æºåˆ†é… |
| worker-0 | ä¸»å®¹å™¨ | slurmd | `slurmd` | ğŸŸ¦ **Slurmå¤–éƒ¨é¡¹ç›®** | Slurmå·¥ä½œèŠ‚ç‚¹å®ˆæŠ¤è¿›ç¨‹ï¼Œæ‰§è¡Œä½œä¸šä»»åŠ¡ |
| login-0 | initå®¹å™¨ | munge | `munged` | ğŸŸ¦ **Slurmå¤–éƒ¨é¡¹ç›®** | Slurmè®¤è¯æœåŠ¡ï¼Œä¸å…¶ä»–èŠ‚ç‚¹é€šä¿¡ |
| login-0 | ä¸»å®¹å™¨ | sshd | `sshd` | ğŸŸ¦ **OpenSSHé¡¹ç›®** | SSHæœåŠ¡ï¼Œæä¾›ç”¨æˆ·ç™»å½•è®¿é—® |
| sconfigcontroller | initå®¹å™¨ | init-dir | - | ğŸŸ© **Soperatoré¡¹ç›®** | åˆå§‹åŒ–é…ç½®ç›®å½•å’Œæƒé™ |
| sconfigcontroller | ä¸»å®¹å™¨ | sconfigctrl | `sconfigcontroller` | ğŸŸ© **Soperatoré¡¹ç›®** | Slurmé…ç½®ç®¡ç†æ§åˆ¶å™¨ |
| populate-jail | ä¸»å®¹å™¨ | populate-jail | jailåˆå§‹åŒ–è„šæœ¬ | ğŸŸ© **Soperatoré¡¹ç›®** | åˆå§‹åŒ–jailç¯å¢ƒï¼Œè®¾ç½®å…±äº«æ–‡ä»¶ç³»ç»Ÿ |
| controller-placeholder | initå®¹å™¨ | munge | `munged` | ğŸŸ¦ **Slurmå¤–éƒ¨é¡¹ç›®** | å¤‡ç”¨è®¤è¯æœåŠ¡ |
| controller-placeholder | ä¸»å®¹å™¨ | slurmctld | `slurmctld` | ğŸŸ¦ **Slurmå¤–éƒ¨é¡¹ç›®** | å¤‡ç”¨Slurmæ§åˆ¶å™¨ï¼ˆé«˜å¯ç”¨ï¼‰ |

### ğŸ¨ **é¢œè‰²æ ‡è®°è¯´æ˜**

- ğŸŸ¦ **Slurmå¤–éƒ¨é¡¹ç›®è¿›ç¨‹**ï¼ˆè“è‰²ï¼‰ï¼š
  - `slurmctld` - Slurm ä¸»æ§åˆ¶å™¨ï¼ˆ[Slurmå®˜æ–¹é¡¹ç›®](https://github.com/SchedMD/slurm)ï¼‰
  - `slurmd` - Slurm å·¥ä½œèŠ‚ç‚¹ï¼ˆ[Slurmå®˜æ–¹é¡¹ç›®](https://github.com/SchedMD/slurm)ï¼‰
  - `munged` - è®¤è¯æœåŠ¡ï¼ˆ[Mungeé¡¹ç›®](https://github.com/dun/munge)ï¼‰
  - `sshd` - SSH æœåŠ¡ï¼ˆ[OpenSSHé¡¹ç›®](https://www.openssh.com/)ï¼‰

- ğŸŸ© **Soperatoré¡¹ç›®è¿›ç¨‹**ï¼ˆç»¿è‰²ï¼‰ï¼š
  - `sconfigcontroller` - Slurm é…ç½®ç®¡ç†æ§åˆ¶å™¨ï¼ˆæœ¬é¡¹ç›®ç¼–è¯‘ç”Ÿæˆï¼‰
  - `populate-jail` - æ–‡ä»¶ç³»ç»Ÿåˆå§‹åŒ–ï¼ˆæœ¬é¡¹ç›®æä¾›ï¼‰
  - `init-dir` - é…ç½®ç›®å½•åˆå§‹åŒ–ï¼ˆæœ¬é¡¹ç›®æä¾›ï¼‰

**æ ¸å¿ƒåŒºåˆ«**ï¼š
- ğŸŸ¦ **Slurm ç»„ä»¶**ï¼šæä¾› HPC ä½œä¸šè°ƒåº¦çš„æ ¸å¿ƒåŠŸèƒ½
- ğŸŸ© **Soperator ç»„ä»¶**ï¼šç®¡ç† Slurm åœ¨ Kubernetes ä¸Šçš„éƒ¨ç½²å’Œè¿è¡Œ

### ğŸ“‹ **Soperator æ ¸å¿ƒäºŒè¿›åˆ¶éƒ¨ç½²ä½ç½®**

| Soperator äºŒè¿›åˆ¶ | å®é™…è¿›ç¨‹å | éƒ¨ç½²ä½ç½® | Pod/å®¹å™¨ | ä½œç”¨ |
|-----------------|-----------|----------|----------|------|
| **slurm-operator** | `slurm_operator` | `soperator` å‘½åç©ºé—´ | `soperator-manager-xxx` | ğŸŸ© Kubernetes Operator ä¸»æ§åˆ¶å™¨ï¼ˆå¿…éœ€ï¼‰ |
| **sconfigcontroller** | `sconfigcontroller` | Slurm é›†ç¾¤å‘½åç©ºé—´ | `sconfigcontroller-xxx` | ğŸŸ© Slurm é…ç½®ç®¡ç†æ§åˆ¶å™¨ |
| **exporter** | `soperator-exporter` | å¯é€‰éƒ¨ç½² | `slurm-exporter-xxx` | ğŸŸ© Prometheus æŒ‡æ ‡å¯¼å‡ºå™¨ |
| **rebooter** | `slurm-rebooter` | å¯é€‰éƒ¨ç½² | `slurm-rebooter-xxx` | ğŸŸ© èŠ‚ç‚¹é‡å¯ç®¡ç†å™¨ |
| **soperatorchecks** | `soperator-checks` | å¯é€‰éƒ¨ç½² | `soperator-checks-xxx` | ğŸŸ© å¥åº·æ£€æŸ¥ç»„ä»¶ |

### ğŸ¢ Kubernetes ç³»ç»Ÿè¿›ç¨‹ï¼ˆéæœ¬é¡¹ç›®ç”Ÿæˆï¼‰
| èŠ‚ç‚¹ | è¿›ç¨‹ | ä½œç”¨ | æ¥æº |
|------|------|------|------|
| control-plane | etcd, kube-apiserver, kube-scheduler, kube-controller-manager | Kubernetes é›†ç¾¤å¤§è„‘å’Œæ§åˆ¶ | Kindest/node åŸºç¡€é•œåƒ |
| æ‰€æœ‰èŠ‚ç‚¹ | kubelet, kube-proxy, containerd | èŠ‚ç‚¹ä»£ç†å’Œå®¹å™¨è¿è¡Œæ—¶ | Kindest/node åŸºç¡€é•œåƒ |

## Control-plane èŠ‚ç‚¹ä¸ºä»€ä¹ˆæ²¡æœ‰ Slurm Podï¼Ÿ

### ğŸ”¸ èŠ‚ç‚¹è¿‡æ»¤ç­–ç•¥

Soperator ä½¿ç”¨**èŠ‚ç‚¹è¿‡æ»¤å™¨**æ¥æ§åˆ¶ Slurm ç»„ä»¶çš„éƒ¨ç½²ä½ç½®ï¼š

```yaml
# SlurmCluster é…ç½®ä¸­çš„èŠ‚ç‚¹è¿‡æ»¤å™¨
spec:
  slurmNodes:
    controller:
      k8sNodeFilterName: cpu  # åªåœ¨å¸¦æœ‰ cpu æ ‡ç­¾çš„èŠ‚ç‚¹ä¸Šéƒ¨ç½²
    worker:
      k8sNodeFilterName: cpu
    login:
      k8sNodeFilterName: cpu
```

### ğŸ”¸ èŠ‚ç‚¹æ ‡ç­¾å¯¹æ¯”

| èŠ‚ç‚¹ | è§’è‰² | æ ‡ç­¾ | æ˜¯å¦è¿è¡ŒSlurm |
|------|------|------|--------------|
| soperator-demo-control-plane | control-plane | `node-role.kubernetes.io/control-plane=` | âŒ ä¸è¿è¡Œ |
| soperator-demo-worker | worker | `nebius.com/node-group-id=node-group-id-here` | âœ… è¿è¡Œ |
| soperator-demo-worker2 | worker | `nebius.com/node-group-id=node-group-id-here` | âœ… è¿è¡Œ |
| soperator-demo-worker3 | worker | `nebius.com/node-group-id=node-group-id-here` | âœ… è¿è¡Œ |

### ğŸ”¸ è¿™æ˜¯æ­£ç¡®çš„è®¾è®¡æ¨¡å¼

**Kubernetes æœ€ä½³å®è·µè¦æ±‚ï¼š**
- **Control-planeèŠ‚ç‚¹**: ä¸“é—¨è¿è¡ŒKubernetesç³»ç»Ÿç»„ä»¶ï¼ˆkube-apiserver, etcdç­‰ï¼‰
- **WorkerèŠ‚ç‚¹**: è¿è¡Œç”¨æˆ·å·¥ä½œè´Ÿè½½ï¼ˆSlurm, åº”ç”¨ç¨‹åºç­‰ï¼‰
- **èŠ‚ç‚¹éš”ç¦»**: é€šè¿‡æ±¡ç‚¹ï¼ˆtaintsï¼‰å’Œå®¹å¿ï¼ˆtolerationsï¼‰å®ç°éš”ç¦»

**ä¼˜åŠ¿ï¼š**
1. **å®‰å…¨æ€§**: ç³»ç»Ÿç»„ä»¶ä¸ç”¨æˆ·å·¥ä½œè´Ÿè½½éš”ç¦»
2. **ç¨³å®šæ€§**: é¿å…ç”¨æˆ·åº”ç”¨å½±å“Kubernetesæ§åˆ¶å¹³é¢
3. **æ€§èƒ½**: ä¸“ç”¨èŠ‚ç‚¹å¤„ç†ç‰¹å®šå·¥ä½œè´Ÿè½½
4. **å¯ç»´æŠ¤æ€§**: ç‹¬ç«‹æ‰©ç¼©å®¹å’Œå‡çº§

## æ¶æ„å±‚æ¬¡è¯¦è§£

### ğŸ”¸ ç¬¬ä¸€å±‚ï¼šä¸»æœº Docker å±‚
- **ä½œç”¨**: è¿è¡Œ Kind é›†ç¾¤èŠ‚ç‚¹å®¹å™¨
- **å®¹å™¨ç±»å‹**: `kindest/node` é•œåƒ
- **æŸ¥çœ‹æ–¹å¼**: `docker ps`
- **ç‰¹ç‚¹**: è¿™æ˜¯åœ¨ä¸»æœºä¸Šå”¯ä¸€èƒ½ç›´æ¥çœ‹åˆ°çš„å®¹å™¨å±‚

### ğŸ”¸ ç¬¬äºŒå±‚ï¼šKubernetes é›†ç¾¤èŠ‚ç‚¹å±‚
- **ä½œç”¨**: Kubernetes é›†ç¾¤çš„åŸºç¡€è®¾æ–½
- **èŠ‚ç‚¹ç±»å‹**: control-plane, worker nodes
- **æŸ¥çœ‹æ–¹å¼**: `kubectl get nodes`
- **ç‰¹ç‚¹**: **ä¸¥æ ¼1:1æ˜ å°„å…³ç³»** - æ¯ä¸ªDockerå®¹å™¨å¯¹åº”ä¸€ä¸ªKubernetesèŠ‚ç‚¹ï¼Œè¿è¡Œå®Œæ•´çš„kubeletå’Œcontainerdç»„ä»¶

### ğŸ”¸ ç¬¬ä¸‰å±‚ï¼šPod å±‚
- **ä½œç”¨**: è¿è¡Œ Slurm é›†ç¾¤ç»„ä»¶
- **Pod ç±»å‹**: controller, login, worker, sconfigcontroller ç­‰
- **æŸ¥çœ‹æ–¹å¼**: `kubectl get pods`
- **ç‰¹ç‚¹**: Kubernetes çš„æœ€å°éƒ¨ç½²å•å…ƒï¼ŒåŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨

### ğŸ”¸ ç¬¬å››å±‚ï¼šå®¹å™¨å±‚
- **ä½œç”¨**: å®é™…è¿è¡Œçš„åº”ç”¨ç¨‹åº
- **å®¹å™¨ç±»å‹**: slurmctld, slurmd, sshd, munge, sconfigctrl ç­‰
- **æŸ¥çœ‹æ–¹å¼**: åœ¨èŠ‚ç‚¹å†…ä½¿ç”¨ `crictl ps`
- **ç‰¹ç‚¹**: çœŸæ­£æ‰§è¡Œ Slurm ç›¸å…³æœåŠ¡çš„å®¹å™¨

## æŸ¥çœ‹å‘½ä»¤é›†åˆ

### ç¬¬ä¸€å±‚ï¼šä¸»æœº Docker å±‚
```bash
# æŸ¥çœ‹æ‰€æœ‰ Docker å®¹å™¨ï¼ˆKind é›†ç¾¤èŠ‚ç‚¹ï¼‰
docker ps

# æŸ¥çœ‹æ‰€æœ‰å®¹å™¨ï¼ˆåŒ…æ‹¬åœæ­¢çš„ï¼‰
docker ps -a

# æŸ¥çœ‹ Kind é›†ç¾¤èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
docker inspect soperator-demo-control-plane
docker inspect soperator-demo-worker
```

### ç¬¬äºŒå±‚ï¼šKubernetes é›†ç¾¤èŠ‚ç‚¹å±‚
```bash
# æŸ¥çœ‹æ‰€æœ‰èŠ‚ç‚¹
kubectl get nodes -o wide

# æŸ¥çœ‹èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
kubectl describe node soperator-demo-worker2

# æŸ¥çœ‹èŠ‚ç‚¹ä¸Šçš„ Pod
kubectl get pods -o wide --field-selector spec.nodeName=soperator-demo-worker2

# æŸ¥çœ‹èŠ‚ç‚¹èµ„æºä½¿ç”¨æƒ…å†µ
kubectl top nodes
```

### ç¬¬ä¸‰å±‚ï¼šPod å±‚
```bash
# æŸ¥çœ‹æ‰€æœ‰å‘½åç©ºé—´çš„ Pod
kubectl get pods --all-namespaces -o wide

# æŸ¥çœ‹ Slurm é›†ç¾¤çš„ Pod
kubectl get pods -n correct-cpu-cluster -o wide

# æŸ¥çœ‹ Pod è¯¦ç»†ä¿¡æ¯
kubectl describe pod controller-0 -n correct-cpu-cluster
kubectl describe pod login-0 -n correct-cpu-cluster

# æŸ¥çœ‹ Pod çš„ YAML é…ç½®
kubectl get pod controller-0 -n correct-cpu-cluster -o yaml

# æŸ¥çœ‹ Pod äº‹ä»¶
kubectl get events -n correct-cpu-cluster --sort-by=.metadata.creationTimestamp
```

### ç¬¬å››å±‚ï¼šå®¹å™¨å±‚ï¼ˆèŠ‚ç‚¹å†…éƒ¨ï¼‰
```bash
# è¿›å…¥æŒ‡å®šèŠ‚ç‚¹æŸ¥çœ‹å®¹å™¨
docker exec -it soperator-demo-worker2 crictl ps
docker exec -it soperator-demo-worker2 crictl images

# æŸ¥çœ‹å®¹å™¨è¯¦ç»†ä¿¡æ¯
docker exec -it soperator-demo-worker2 crictl inspect <container-id>

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker exec -it soperator-demo-worker2 crictl logs <container-id>

# åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸ŠæŸ¥çœ‹å®¹å™¨
for node in soperator-demo-control-plane soperator-demo-worker soperator-demo-worker2 soperator-demo-worker3; do
    echo "=== $node ==="
    docker exec $node crictl ps | grep -E "(slurm|login|munge|sconfig)"
done
```

## ç»„åˆæŸ¥çœ‹å‘½ä»¤

### æŸ¥çœ‹æ‰€æœ‰ Slurm ç›¸å…³å®¹å™¨
```bash
#!/bin/bash
echo "=== Slurm å®¹å™¨åˆ†å¸ƒæƒ…å†µ ==="
for node in $(kubectl get nodes -o name | cut -d'/' -f2); do
    echo "ğŸ“ Node: $node"
    docker exec $node crictl ps | grep -E "(slurm|login|munge|sconfig|jail)" || echo "  æ—  Slurm å®¹å™¨"
    echo ""
done
```

### æŸ¥çœ‹ Pod å’Œå®¹å™¨æ˜ å°„å…³ç³»
```bash
kubectl get pods -n correct-cpu-cluster -o custom-columns=NAME:.metadata.name,READY:.status.readyReplicas,CONTAINERS:.spec.containers[*].name,INIT_CONTAINERS:.spec.initContainers[*].name
```

## å½“å‰ Pod çŠ¶æ€åˆ†æ

æ ¹æ®å½“å‰é›†ç¾¤çŠ¶æ€ï¼š

| Docker å®¹å™¨ | Kubernetes èŠ‚ç‚¹ | Pod åç§° | çŠ¶æ€ | å®¹å™¨æ•° | ä½œç”¨ |
|-------------|----------------|---------|------|--------|------|
| soperator-demo-worker3 | soperator-demo-worker3 | controller-0 | CrashLoopBackOff | 1/2 | Slurm ä¸»æ§åˆ¶å™¨ï¼ˆæœ‰é—®é¢˜ï¼‰ |
| soperator-demo-worker | soperator-demo-worker | controller-placeholder-7lc4l | Running | 2/2 | Slurm æ§åˆ¶å™¨å ä½ç¬¦ |
| soperator-demo-worker2 | soperator-demo-worker2 | controller-placeholder-849m5 | Running | 2/2 | Slurm æ§åˆ¶å™¨å ä½ç¬¦ |
| soperator-demo-worker3 | soperator-demo-worker3 | controller-placeholder-mdclb | Running | 2/2 | Slurm æ§åˆ¶å™¨å ä½ç¬¦ |
| soperator-demo-worker2 | soperator-demo-worker2 | login-0 | Running | 2/2 | SSH ç™»å½•èŠ‚ç‚¹ |
| soperator-demo-worker | soperator-demo-worker | worker-0 | Running | 1/1 | Slurm å·¥ä½œèŠ‚ç‚¹ |
| soperator-demo-worker | soperator-demo-worker | sconfigcontroller-86cc985fc-5bswf | Running | 1/1 | Slurm é…ç½®æ§åˆ¶å™¨ |
| soperator-demo-worker2 | soperator-demo-worker2 | populate-jail-5f4kh | Completed | 0/1 | åˆå§‹åŒ–ä½œä¸šå®¹å™¨ |

## Kind å·¥ä½œåŸç†è¯¦è§£

### ğŸ”¸ Kind æ˜¯ä»€ä¹ˆï¼Ÿ
Kind (Kubernetes in Docker) å°† Kubernetes ç»„ä»¶ç›´æ¥è¿è¡Œåœ¨ Docker å®¹å™¨å†…ï¼Œè€Œä¸æ˜¯ï¿½ï¿½ï¿½ç”¨è™šæ‹Ÿæœºã€‚æ¯ä¸ª Kind å®¹å™¨å°±æ˜¯ä¸€ä¸ªå®Œæ•´çš„ Kubernetes èŠ‚ç‚¹ã€‚

### ğŸ”¸ 1:1 æ˜ å°„å…³ç³»
```
Docker å®¹å™¨                    Kubernetes èŠ‚ç‚¹
soperator-demo-control-plane  â†” soperator-demo-control-plane
soperator-demo-worker         â†” soperator-demo-worker
soperator-demo-worker2        â†” soperator-demo-worker2
soperator-demo-worker3        â†” soperator-demo-worker3
```

### ğŸ”¸ æ¯ä¸ªå®¹å™¨å†…è¿è¡Œçš„ç»„ä»¶
- **æ§åˆ¶å¹³é¢å®¹å™¨**: kube-apiserver, kube-controller-manager, kube-scheduler, etcd, kubelet, kube-proxy
- **å·¥ä½œèŠ‚ç‚¹å®¹å™¨**: kubelet, kube-proxy, containerd, ä»¥åŠæ‚¨çš„ Pod

### ğŸ”¸ ä¸ºä»€ä¹ˆå¯ä»¥ç”¨ kubectl ç›´æ¥æ“ä½œï¼Ÿ
Kind é€šè¿‡ç«¯å£è½¬å‘å°†ä¸»æœºè¿æ¥åˆ°æ§åˆ¶å¹³é¢å®¹å™¨ï¼š
```
ä¸»æœº:127.0.0.1:62377 â†’ å®¹å™¨:6443 (kube-apiserver)
```

### ğŸ”¸ éªŒè¯1:1æ˜ å°„
```bash
# æŸ¥çœ‹ Docker å®¹å™¨
docker ps | grep soperator-demo

# æŸ¥çœ‹ Kubernetes èŠ‚ç‚¹
kubectl get nodes -o wide

# éªŒè¯IPåœ°å€å¯¹åº”
docker exec soperator-demo-worker2 hostname -I
kubectl get node soperator-demo-worker2 -o jsonpath='{.status.addresses[?(@.type=="InternalIP")].address}'
```

## å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆåœ¨ä¸»æœºä¸Šçœ‹ä¸åˆ° Slurm å®¹å™¨ï¼Ÿ
A: Slurm å®¹å™¨è¿è¡Œåœ¨ Kind é›†ç¾¤èŠ‚ç‚¹å®¹å™¨å†…éƒ¨ï¼Œéœ€è¦è¿›å…¥èŠ‚ç‚¹å®¹å™¨åä½¿ç”¨ `crictl` æŸ¥çœ‹ã€‚

### Q: å¦‚ä½•æŸ¥çœ‹å´©æºƒå®¹å™¨çš„æ—¥å¿—ï¼Ÿ
A:
```bash
# æŸ¥çœ‹ Pod æ—¥å¿—
kubectl logs controller-0 -n correct-cpu-cluster

# æŸ¥çœ‹ç‰¹å®šå®¹å™¨æ—¥å¿—
kubectl logs controller-0 -c slurmctld -n correct-cpu-cluster

# æŸ¥çœ‹èŠ‚ç‚¹å†…å®¹å™¨æ—¥å¿—
docker exec soperator-demo-control-plane crictl logs <container-id>
```

### Q: å¦‚ä½•è¿›å…¥å®¹å™¨è°ƒè¯•ï¼Ÿ
A:
```bash
# è¿›å…¥ Pod å†…çš„æŒ‡å®šå®¹å™¨
kubectl exec -it controller-0 -c slurmctld -n correct-cpu-cluster -- /bin/bash

# è¿›å…¥èŠ‚ç‚¹å†…çš„å®¹å™¨
docker exec -it soperator-demo-control-plane crictl exec <container-id> /bin/bash
```

## æ€»ç»“

è¿™ä¸ªå¤šå±‚å®¹å™¨æ¶æ„æä¾›äº†å®Œæ•´çš„ Kubernetes é›†ç¾¤ç¯å¢ƒï¼ŒåŒæ—¶ä¿æŒäº†ä¸ä¸»æœºçš„éš”ç¦»ã€‚ç†è§£è¿™ä¸ªå±‚æ¬¡ç»“æ„å¯¹äºæœ‰æ•ˆè°ƒè¯•å’Œç®¡ç† Slurm é›†ç¾¤è‡³å…³é‡è¦ã€‚

---

# Soperator ä½¿ç”¨åœºæ™¯è¯¦è§£

## ğŸ¯ æ ¸å¿ƒä½¿ç”¨åœºæ™¯

Soperator æ˜¯ä¸€ä¸ª Kubernetes Operatorï¼Œç”¨äºåœ¨ Kubernetes ä¸Šè¿è¡Œå’Œç®¡ç† Slurm HPC é›†ç¾¤ã€‚

### ğŸ“ ç”¨æˆ·æäº¤ä½œä¸šåœºæ™¯

#### **æ–¹å¼1ï¼šé€šè¿‡ç™»å½•èŠ‚ç‚¹ï¼ˆæ¨èï¼‰**
```bash
# SSH ç™»å½•åˆ° login-0 èŠ‚ç‚¹
ssh -p 30022 soperator@localhost

# å‡†å¤‡ä½œä¸šè„šæœ¬
cat > my_job.sh << EOF
#!/bin/bash
#SBATCH --ntasks=2
#SBATCH --time=10:00
#SBATCH --output=job_%j.out
./my_hpc_application
EOF

# æäº¤ä½œä¸š
sbatch my_job.sh

# æŸ¥çœ‹ä½œä¸šçŠ¶æ€
squeue
scontrol show job <job_id>

# æŸ¥çœ‹ç»“æœ
cat job_<job_id>.out
```

#### **æ–¹å¼2ï¼šé€šè¿‡ kubectl exec**
```bash
kubectl exec -it login-0 -n correct-cpu-cluster -- bash
sbatch job_script.sh
srun --ntasks=4 ./my_application
```

### ğŸ”§ é›†ç¾¤ç®¡ç†åœºæ™¯

#### **ç®¡ç†å‘˜æ—¥å¸¸è¿ç»´**
```bash
# 1. é›†ç¾¤çŠ¶æ€æ£€æŸ¥
kubectl get slurmclusters -A
kubectl describe slurmcluster correct-cpu-cluster -n correct-cpu-cluster

# 2. ç›‘æ§ Pod çŠ¶æ€
kubectl get pods -n correct-cpu-cluster
kubectl logs -n correct-cpu-cluster -l app.kubernetes.io/component=controller

# 3. é€šè¿‡ Helm ç®¡ç†é›†ç¾¤é…ç½®
helm upgrade correct-cpu-cluster ./helm-charts/slurm-cluster -n correct-cpu-cluster
```

### ğŸ”„ æ‰©å®¹ç¼©å®¹åœºæ™¯

#### **æ‰‹åŠ¨æ‰©å®¹ç¼©å®¹**
```bash
# 1. ç¼–è¾‘ SlurmCluster é…ç½®
kubectl edit slurmcluster correct-cpu-cluster -n correct-cpu-cluster

# 2. ä¿®æ”¹ worker æ•°é‡
spec:
  slurmNodes:
    worker:
      size: 4  # ä» 2 æ‰©å®¹åˆ° 4

# 3. åº”ç”¨é…ç½®
kubectl apply -f updated-cluster.yaml

# 4. ç›‘æ§æ‰©å®¹è¿›åº¦
kubectl get pods -n correct-cpu-cluster -w
```

#### **è‡ªåŠ¨æ‰©å®¹ç¼©å®¹**
```yaml
# é€šè¿‡ SlurmCluster CRD é…ç½®
apiVersion: slurm.nebius.ai/v1
kind: SlurmCluster
metadata:
  name: correct-cpu-cluster
spec:
  slurmNodes:
    worker:
      size: 2  # åˆå§‹å¤§å°
      maxUnavailable: 20%  # æ»šåŠ¨æ›´æ–°ç­–ç•¥
```

### ğŸ“Š å…¸å‹ä½¿ç”¨æµç¨‹

#### **ç§‘ç ”ç”¨æˆ·æ—¥å¸¸ä½¿ç”¨**
```bash
# 1. ç™»å½•é›†ç¾¤
ssh -p 30022 user@research-cluster.company.com

# 2. äº¤äº’å¼è°ƒè¯•
srun --pty --ntasks=1 bash

# 3. æ‰¹é‡ä½œä¸šæäº¤
sbatch --array=1-100%10 array_job.sh

# 4. ç›‘æ§ä½œä¸š
squeue -u $USER
sstat -j <job_id>

# 5. è·å–ç»“æœ
scp user@research-cluster.company.com:~/results/* ./
```

#### **é›†ç¾¤ç®¡ç†å‘˜æ—¥å¸¸è¿ç»´**
```bash
# 1. é›†ç¾¤çŠ¶æ€æ£€æŸ¥
kubectl get slurmclusters -A
kubectl describe slurmcluster my-cluster -n my-namespace

# 2. é…ç½®æ›´æ–°
helm upgrade my-cluster ./helm-charts/slurm-cluster \
  --set slurmNodes.worker.size=10 \
  --set slurmNodes.controller.resources.memory=2Gi

# 3. æ•…éšœæ’æŸ¥
kubectl logs -n my-namespace controller-0
kubectl exec -it login-0 -n my-namespace -- scontrol show nodes

# 4. æ€§èƒ½ç›‘æ§
kubectl top pods -n my-namespace
kubectl get events -n my-namespace --sort-by=.metadata.creationTimestamp
```

### ğŸ¯ å®é™…ç”Ÿäº§ç¯å¢ƒåœºæ™¯

#### **åœºæ™¯1ï¼šæœºå™¨å­¦ä¹ è®­ç»ƒä½œä¸š**
```bash
# ç ”ç©¶å‘˜æäº¤åˆ†å¸ƒå¼è®­ç»ƒä½œä¸š
sbatch --ntasks=8 --cpus-per-task=4 --mem=32G \
       --output=training_%j.out \
       --time=04:00:00 \
       ./distributed_training.sh
```

#### **åœºæ™¯2ï¼šåŸºå› ç»„åˆ†ææ‰¹å¤„ç†**
```bash
# ç”Ÿç‰©ä¿¡æ¯å­¦å®¶æäº¤å¤§æ‰¹é‡åˆ†æä½œä¸š
sbatch --array=1-1000%50 \
       --cpus-per-task=8 \
       --mem=16G \
       --partition=batch \
       ./genome_analysis.sh
```

#### **åœºæ™¯3ï¼šåŠ¨æ€èµ„æºæ‰©å®¹**
```bash
# ç®¡ç†å‘˜æ ¹æ®ä½œä¸šé˜Ÿåˆ—é•¿åº¦åŠ¨æ€æ‰©å®¹
kubectl patch slurmcluster ml-cluster -n ml-namespace \
  --type='merge' \
  -p='{"spec":{"slurmNodes":{"worker":{"size":15}}}}'

# ç›‘æ§æ‰©å®¹è¿›åº¦
watch kubectl get pods -n ml-namespace -l app.kubernetes.io/component=worker
```

## ğŸ’¡ æ ¸å¿ƒä»·å€¼

**Soperator å°†ä¼ ç»Ÿ HPC Slurm å·¥ä½œè´Ÿè½½å®¹å™¨åŒ–ï¼Œåœ¨ Kubernetes ä¸Šè¿è¡Œï¼š**

- **ç”¨æˆ·å±‚é¢**: ä½¿ç”¨æ ‡å‡† Slurm å‘½ä»¤ï¼Œæ— å­¦ä¹ æˆæœ¬
- **ç®¡ç†å‘˜å±‚é¢**: é€šè¿‡ kubectl å’Œ helm ç®¡ç†é›†ç¾¤
- **è‡ªåŠ¨åŒ–å±‚é¢**: è‡ªåŠ¨æ‰©å®¹ã€æ•…éšœæ¢å¤ã€å¼¹æ€§è°ƒåº¦

---

# Slurm CPU é›†ç¾¤æ¼”ç¤ºè„šæœ¬

è¿™ä¸ªç›®å½•åŒ…å«äº† Slurm on Kubernetes CPU é›†ç¾¤çš„å®Œæ•´æ¼”ç¤ºè„šæœ¬ã€‚

## ğŸ“‹ è„šæœ¬ä½¿ç”¨é¡ºåº

### 1ï¸âƒ£ åŸºç¡€é›†ç¾¤æ£€æŸ¥
```bash
./01-check-cluster.sh
```
æ£€æŸ¥å‘½åç©ºé—´ã€Podã€æœåŠ¡å’Œå­˜å‚¨çš„åŸºæœ¬çŠ¶æ€ã€‚

### 2ï¸âƒ£ ç™»å½•èŠ‚ç‚¹è®¿é—®
```bash
./02-access-login.sh
```
éªŒè¯ç™»å½•èŠ‚ç‚¹çš„ç¯å¢ƒã€å­˜å‚¨æŒ‚è½½å’Œç½‘ç»œè¿é€šæ€§ã€‚

### 3ï¸âƒ£ Slurm çŠ¶æ€åˆ†æ
```bash
./03-slurm-status-real.sh
```
æ·±å…¥åˆ†æ Slurm é›†ç¾¤çš„çœŸå®éƒ¨ç½²çŠ¶æ€å’Œæ¶æ„ç»„ä»¶ã€‚

### 4ï¸âƒ£ ä½œä¸šè°ƒåº¦æ¼”ç¤º
```bash
./04-job-demo.sh
```
å±•ç¤º Slurm ä½œä¸šè°ƒåº¦æ¦‚å¿µå’Œå®¹å™¨åŒ–ä½œä¸šæ‰§è¡Œã€‚

### 5ï¸âƒ£ éƒ¨ç½²æ€»ç»“
```bash
./05-final-status.sh
```
æä¾›å®Œæ•´çš„éƒ¨ç½²æ€»ç»“å’Œä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®ã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡è¿™äº›è„šæœ¬ï¼Œä½ å°†å­¦ä¹ åˆ°ï¼š

- âœ… Soperator çº¯ CPU é›†ç¾¤æ”¯æŒèƒ½åŠ›
- âœ… HPC å·¥ä½œè´Ÿè½½å®¹å™¨åŒ–æµç¨‹
- âœ… Kubernetes ç®¡ç† Slurm æ¶æ„çš„æ–¹æ³•
- âœ… äº‘åŸç”Ÿ HPC åŸºç¡€è®¾æ–½æ¦‚å¿µ
- âœ… å®é™…ç”Ÿäº§ç¯å¢ƒä¸­çš„æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ

## âš ï¸ æŠ€æœ¯è¯´æ˜

å½“å‰éƒ¨ç½²é‡åˆ°ä¸€äº›é›†æˆæŒ‘æˆ˜ï¼Œè¿™äº›éƒ½æ˜¯å¤æ‚ HPC å®¹å™¨åŒ–éƒ¨ç½²ä¸­çš„å¸¸è§é—®é¢˜ï¼š

- DNS SRV è®°å½•è§£æé…ç½®
- Munge è®¤è¯ç³»ç»Ÿè®¾ç½®
- Slurm é…ç½®æ–‡ä»¶ä¼˜åŒ–

è¿™äº›æŒ‘æˆ˜æœ¬èº«å°±æ˜¯å®è´µçš„å­¦ä¹ ç»éªŒï¼Œåæ˜ äº†çœŸå®ç”Ÿäº§ç¯å¢ƒä¸­çš„å¤æ‚æ€§ã€‚

## ğŸš€ å¼€å§‹ä½¿ç”¨

ä»ç¬¬1æ­¥å¼€å§‹ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰è„šæœ¬ï¼š

```bash
./01-check-cluster.sh && ./02-access-login.sh && ./03-slurm-status-real.sh && ./04-job-demo.sh && ./05-final-status.sh
```

æˆ–è€…ä¸€æ¬¡æ€§è¿è¡Œå®Œæ•´æ¼”ç¤ºï¼š

```bash
for script in 0*.sh; do echo "=== è¿è¡Œ $script ===" && ./$script && echo ""; done
```

äº«å—ä½ çš„ HPC å®¹å™¨åŒ–å­¦ä¹ ä¹‹æ—…ï¼ğŸ‰